{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:54:08.549521Z",
     "start_time": "2018-10-24T17:54:08.541543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ctypes\n",
    "import gmpy2\n",
    "from gmpy2 import mpz\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers.core import Activation, Dense\n",
    "from keras.layers import Flatten, Reshape,LSTM,GRU, Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T16:05:13.222241Z",
     "start_time": "2018-10-24T16:05:13.217255Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    index_set = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    X_batch = X_train[index_set]\n",
    "    y_batch = y_train[index_set]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symmetric (secret-key) encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model `crypto1` (Google)\n",
    "\n",
    "This model was build according to the specifications from Google's paper *Learning to protect communications with adversarial neural cryptography*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T16:55:24.834360Z",
     "start_time": "2018-10-24T16:55:24.830369Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'crypto1'\n",
    "\n",
    "# Set up the crypto parameters: message, key, and ciphertext bit lengths\n",
    "m_bits = 16\n",
    "k_bits = 16\n",
    "c_bits = 16\n",
    "pad = 'same'\n",
    "\n",
    "# Compute the size of the message space\n",
    "m_train = 2**(m_bits) #+ k_bits)\n",
    "\n",
    "alice_file = 'models/crypto/' + model_name + '-alice'\n",
    "bob_file = 'models/crypto/' + model_name + '-bob'\n",
    "eve_file = 'models/crypto/' + model_name + '-eve'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"alice\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32)           0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 32, 1)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32, 16)       1152        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32, 64)       20736       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 128)          98816       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4096)         528384      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           65552       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 715,696\n",
      "Trainable params: 715,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"bob\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           1056        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 32, 1)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 32, 16)       1152        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 32, 64)       20736       lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 128)          98816       lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4096)         528384      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4096)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           65552       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 715,696\n",
      "Trainable params: 715,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"eve\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 32, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 32, 16)            1152      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32, 64)            20736     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 126,960\n",
      "Trainable params: 126,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "##### Alice network #####\n",
    "#\n",
    "ainput0 = Input(shape=(m_bits,)) #message\n",
    "ainput1 = Input(shape=(k_bits,)) #key\n",
    "ainput = concatenate([ainput0, ainput1], axis=1)\n",
    "\n",
    "adense1 = Dense(units=(m_bits + k_bits))(ainput)\n",
    "adense1a = Activation('tanh')(adense1)\n",
    "areshape = Reshape((m_bits + k_bits, 1,))(adense1a)\n",
    "\n",
    "x = LSTM(16,return_sequences=True)(areshape)\n",
    "x = LSTM(64,return_sequences=True)(x)\n",
    "x = LSTM(128)(x)\n",
    "x = Dense(4096,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "aoutput = Dense(16,activation='relu')(x)\n",
    "alice = Model([ainput0, ainput1], aoutput, name='alice')\n",
    "alice.summary()\n",
    "\n",
    "\n",
    "##### Bob network #####\n",
    "#\n",
    "binput0 = Input(shape=(c_bits,)) #ciphertext\n",
    "binput1 = Input(shape=(k_bits,)) #key\n",
    "binput = concatenate([binput0, binput1], axis=1)\n",
    "\n",
    "bdense1 = Dense(units=(c_bits + k_bits))(binput)\n",
    "bdense1a = Activation('tanh')(bdense1)\n",
    "\n",
    "breshape = Reshape((c_bits + k_bits, 1,))(bdense1a)\n",
    "\n",
    "\n",
    "x = LSTM(16,return_sequences=True)(breshape)\n",
    "x = LSTM(64,return_sequences=True)(x)\n",
    "x = LSTM(128)(x)\n",
    "x = Dense(4096,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "boutput = Dense(16,activation='relu')(x)\n",
    "\n",
    "bob = Model([binput0, binput1], boutput, name='bob')\n",
    "bob.summary()\n",
    "\n",
    "\n",
    "# Eve network\n",
    "#\n",
    "einput = Input(shape=(c_bits,)) #ciphertext only\n",
    "\n",
    "edense1 = Dense(units=(c_bits + k_bits))(einput)\n",
    "edense1a = Activation('tanh')(edense1)\n",
    "\n",
    "edense2 = Dense(units=(c_bits + k_bits))(edense1a)\n",
    "edense2a = Activation('tanh')(edense2)\n",
    "\n",
    "ereshape = Reshape((c_bits + k_bits, 1,))(edense2a)\n",
    "\n",
    "\n",
    "x = LSTM(16,return_sequences=True)(ereshape)\n",
    "x = LSTM(64,return_sequences=True)(x)\n",
    "x = LSTM(128)(x)\n",
    "x = Dense(32,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "eoutput = Dense(16,activation='relu')(x)\n",
    "eve = Model(einput, eoutput, name='eve')\n",
    "eve.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:40:45.710471Z",
     "start_time": "2018-10-24T17:40:45.635579Z"
    }
   },
   "outputs": [],
   "source": [
    "alice.compile(loss='mse', optimizer='sgd')\n",
    "bob.compile(loss='mse', optimizer='sgd')\n",
    "eve.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:22:25.960249Z",
     "start_time": "2018-10-24T17:22:25.957253Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    alice.summary()\n",
    "    bob.summary()\n",
    "    eve.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T16:55:31.515986Z",
     "start_time": "2018-10-24T16:55:31.340478Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/.local/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "# Establish the communication channels by linking inputs to outputs\n",
    "#\n",
    "aliceout = alice([ainput0, ainput1])\n",
    "bobout = bob( [aliceout, binput1] )# bob sees ciphertext AND key\n",
    "eveout = eve( aliceout )# eve doesn't see the key, only the cipher\n",
    "\n",
    "# Loss for Eve is just L1 distance between ainput0 and eoutput. The sum\n",
    "# is taken over all the bits in the message. The quantity inside the K.mean()\n",
    "# is per-example loss. We take the average across the entire mini-batch\n",
    "#\n",
    "eveloss = K.mean(  K.sum(K.abs(ainput0 - eveout), axis=-1)  )\n",
    "\n",
    "# Loss for Alice-Bob communication depends on Bob's reconstruction, but\n",
    "# also on Eve's ability to decrypt the message. Eve should do no better\n",
    "# than random guessing, so on average she will guess half the bits right.\n",
    "#\n",
    "bobloss = K.mean(  K.sum(K.abs(ainput0 - bobout), axis=-1)  )\n",
    "abeloss = bobloss + K.square(m_bits/2 - eveloss)/( (m_bits//2)**2 )\n",
    "\n",
    "# Optimizer and compilation\n",
    "#\n",
    "abeoptim = RMSprop(lr=0.001)\n",
    "eveoptim = RMSprop(lr=0.001) #default 0.001\n",
    "\n",
    "\n",
    "# Build and compile the ABE model, used for training Alice-Bob networks\n",
    "#\n",
    "abemodel = Model([ainput0, ainput1, binput1], bobout, name='abemodel')\n",
    "abemodel.add_loss(abeloss)\n",
    "abemodel.compile(optimizer=abeoptim)\n",
    "\n",
    "\n",
    "# Build and compile the EVE model, used for training Eve net (with Alice frozen)\n",
    "#\n",
    "alice.trainable = False\n",
    "evemodel = Model([ainput0, ainput1], eveout, name='evemodel')\n",
    "evemodel.add_loss(eveloss)\n",
    "evemodel.compile(optimizer=eveoptim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / save / restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T16:25:54.442748Z",
     "start_time": "2018-10-24T16:25:54.438759Z"
    }
   },
   "outputs": [],
   "source": [
    "abelosses = []\n",
    "boblosses = []\n",
    "evelosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:34:58.910922Z",
     "start_time": "2018-10-20T13:32:12.794003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epochs with 128 batches of size 512\n",
      "WARNING:tensorflow:From /home/lenovo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch   0:  99% | abe: 7.552 | eve: 7.620 | bob: 7.529\n",
      "Epoch   1:  99% | abe: 6.960 | eve: 7.227 | bob: 6.931\n",
      "Epoch   2:  99% | abe: 6.821 | eve: 6.922 | bob: 6.779\n",
      "Epoch   3:  99% | abe: 6.664 | eve: 6.731 | bob: 6.616\n",
      "Epoch   4:  99% | abe: 6.492 | eve: 6.574 | bob: 6.433\n",
      "Epoch   5:  99% | abe: 6.464 | eve: 6.439 | bob: 6.398\n",
      "Epoch   6:  99% | abe: 6.412 | eve: 6.333 | bob: 6.334\n",
      "Epoch   7:  99% | abe: 6.348 | eve: 6.220 | bob: 6.263\n",
      "Epoch   8:  99% | abe: 6.210 | eve: 6.080 | bob: 6.109\n",
      "Epoch   9:  99% | abe: 6.025 | eve: 5.966 | bob: 5.914\n",
      "Epoch  10:  13% | abe: 5.910 | eve: 5.917 | bob: 5.787"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 512\n",
    "n_batches = m_train // batch_size\n",
    "\n",
    "abecycles = 1\n",
    "evecycles = 2\n",
    "\n",
    "epoch = 0\n",
    "print(\"Training for\", n_epochs, \"epochs with\", n_batches, \"batches of size\", batch_size)\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    abelosses0 = []\n",
    "    boblosses0 = []\n",
    "    evelosses0 = []\n",
    "    for iteration in range(n_batches):\n",
    "        \n",
    "        # Train the A-B+E network\n",
    "        #\n",
    "        alice.trainable = True\n",
    "        for cycle in range(abecycles):\n",
    "            # Select a random batch of messages, and a random batch of keys\n",
    "            #\n",
    "            m_batch = np.random.randint(0, 2, m_bits * batch_size).reshape(batch_size, m_bits)\n",
    "            k_batch = np.random.randint(0, 2, k_bits * batch_size).reshape(batch_size, k_bits)\n",
    "            loss = abemodel.train_on_batch([m_batch, k_batch, k_batch], None)\n",
    "        \n",
    "        abelosses0.append(loss)\n",
    "        abelosses.append(loss)\n",
    "        abeavg = np.mean(abelosses0)\n",
    "            \n",
    "        # Evaluate Bob's ability to decrypt a message\n",
    "        m_enc = alice.predict([m_batch, k_batch])\n",
    "        m_dec = bob.predict([m_enc, k_batch])\n",
    "        loss = np.mean(  np.sum( np.abs(m_batch - m_dec), axis=-1)  )\n",
    "        boblosses0.append(loss)\n",
    "        boblosses.append(loss)\n",
    "        bobavg = np.mean(boblosses0)\n",
    "        \n",
    "        # Train the EVE network\n",
    "        #\n",
    "        alice.trainable = False\n",
    "        for cycle in range(evecycles):\n",
    "            m_batch = np.random.randint(0, 2, m_bits * batch_size).reshape(batch_size, m_bits)\n",
    "            k_batch = np.random.randint(0, 2, k_bits * batch_size).reshape(batch_size, k_bits)\n",
    "            loss = evemodel.train_on_batch([m_batch, k_batch], None)\n",
    "        \n",
    "        evelosses0.append(loss)\n",
    "        evelosses.append(loss)\n",
    "        eveavg = np.mean(evelosses0)\n",
    "        \n",
    "        if iteration % max(1, (n_batches // 100)) == 0:\n",
    "            print(\"\\rEpoch {:3}: {:3}% | abe: {:2.3f} | eve: {:2.3f} | bob: {:2.3f}\".format(\n",
    "                epoch, 100 * iteration // n_batches, abeavg, eveavg, bobavg), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    print()\n",
    "    epoch += 1\n",
    "    \n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:35:32.154853Z",
     "start_time": "2018-10-20T13:35:31.667925Z"
    }
   },
   "outputs": [],
   "source": [
    "steps = -1\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(abelosses[:steps], label='A-B')\n",
    "plt.plot(evelosses[:steps], label='Eve')\n",
    "plt.plot(boblosses[:steps], label='Bob')\n",
    "plt.xlabel(\"Iterations\", fontsize=13)\n",
    "plt.ylabel(\"Loss\", fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#plt.savefig(\"images/\" + model_name + \".png\", transparent=True) #dpi=100\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:36:55.793226Z",
     "start_time": "2018-10-20T13:36:54.997151Z"
    }
   },
   "outputs": [],
   "source": [
    "if False: #Don't overwrite by accident\n",
    "    alice.save(alice_file + '.h5', overwrite=True)\n",
    "    bob.save(bob_file + '.h5', overwrite=True)\n",
    "    eve.save(eve_file + '.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:50:10.371092Z",
     "start_time": "2018-10-24T17:50:08.651549Z"
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 10000\n",
    "\n",
    "m_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "k_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "\n",
    "m_enc = alice.predict([m_batch, k_batch])\n",
    "m_dec = (bob.predict([m_enc, k_batch]) > 0.5).astype(int)\n",
    "m_att = (eve.predict(m_enc) > 0.5).astype(int)\n",
    "\n",
    "bdiff = np.abs(m_batch - m_dec)\n",
    "bsum = np.sum(bdiff, axis=-1)\n",
    "ediff = np.abs(m_batch - m_att)\n",
    "esum = np.sum(ediff, axis=-1)\n",
    "\n",
    "print(\"Bob % correct: \", 100.0*np.sum(bsum == 0) / n_examples, '%')\n",
    "print(\"Eve % correct: \", 100.0*np.sum(esum == 0) / n_examples, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze Alice-Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:40:52.452236Z",
     "start_time": "2018-10-24T17:40:52.185923Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    alice = load_model(alice_file + '.h5')\n",
    "    bob = load_model(bob_file + '.h5')\n",
    "    eve = load_model(eve_file + '.h5')\n",
    "\n",
    "aliceout = alice([ainput0, ainput1])\n",
    "bobout = bob( [aliceout, binput1] )# bob sees ciphertext AND key\n",
    "eveout = eve( aliceout )# eve doesn't see the key, only the cipher\n",
    "\n",
    "eveloss = K.mean(  K.sum(K.abs(ainput0 - eveout), axis=-1)  )\n",
    "bobloss = K.mean(  K.sum(K.abs(ainput0 - bobout), axis=-1)  )\n",
    "abeloss = bobloss + K.square(m_bits/2 - eveloss)/( (m_bits//2)**2 )\n",
    "\n",
    "abeoptim = RMSprop(lr=0.001)\n",
    "eveoptim = Adam()#RMSprop(lr=0.001) #default 0.001\n",
    "\n",
    "abemodel = Model([ainput0, ainput1, binput1], bobout, name='abemodel')\n",
    "abemodel.add_loss(abeloss)\n",
    "abemodel.compile(optimizer=abeoptim)\n",
    "\n",
    "alice.trainable = False\n",
    "evemodel = Model([ainput0, ainput1], eveout, name='evemodel')\n",
    "evemodel.add_loss(eveloss)\n",
    "evemodel.compile(optimizer=eveoptim)\n",
    "\n",
    "abelosses = []\n",
    "boblosses = []\n",
    "evelosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:42:53.191446Z",
     "start_time": "2018-10-24T17:40:52.740728Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 512\n",
    "n_batches = m_train // batch_size\n",
    "\n",
    "epoch = 0\n",
    "print(\"Training for\", n_epochs, \"epochs with\", n_batches, \"batches of size\", batch_size)\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    abelosses0 = []\n",
    "    boblosses0 = []\n",
    "    evelosses0 = []\n",
    "    for iteration in range(n_batches):\n",
    "        # Train Eve model only\n",
    "        #\n",
    "        alice.trainable = False\n",
    "        m_batch = np.random.randint(0, 2, m_bits * batch_size).reshape(batch_size, m_bits)\n",
    "        k_batch = np.random.randint(0, 2, k_bits * batch_size).reshape(batch_size, k_bits)\n",
    "        eveloss = evemodel.train_on_batch([m_batch, k_batch], None)\n",
    "        evelosses0.append(eveloss)\n",
    "        evelosses.append(eveloss)\n",
    "        eveavg = np.mean(evelosses0)\n",
    "        \n",
    "        # Evaluate Bob's ability to decrypt a message\n",
    "        m_enc = alice.predict([m_batch, k_batch])\n",
    "        m_dec = bob.predict([m_enc, k_batch])\n",
    "        bobloss = np.mean(  np.sum( np.abs(m_batch - m_dec), axis=-1)  )\n",
    "        boblosses0.append(bobloss)\n",
    "        boblosses.append(bobloss)\n",
    "        bobavg = np.mean(boblosses0)\n",
    "        \n",
    "        # Evaluate the ABE loss\n",
    "        abeloss = bobloss + ((m_bits/2 - eveloss)**2) / ( (m_bits//2)**2 )\n",
    "        abelosses0.append(abeloss)\n",
    "        abelosses.append(abeloss)\n",
    "        abeavg = np.mean(abelosses0)\n",
    "        \n",
    "        if iteration % max(1, (n_batches // 100)) == 0:\n",
    "            print(\"\\rEpoch {:3}: {:3}% | abe: {:2.3f} | eve: {:2.3f} | bob: {:2.3f}\".format(\n",
    "                epoch, 100 * iteration // n_batches, abeavg, eveavg, bobavg), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    print()\n",
    "    epoch += 1\n",
    "    \n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:42:57.033465Z",
     "start_time": "2018-10-24T17:42:56.896804Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps = -1\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(abelosses[:steps], label='A-B')\n",
    "plt.plot(evelosses[:steps], label='Eve')\n",
    "plt.plot(boblosses[:steps], label='Bob')\n",
    "plt.xlabel(\"Iterations\", fontsize=13)\n",
    "plt.ylabel(\"Loss\", fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "\n",
    "#plt.savefig(\"images/\" + model_name + \"-eve1.png\", transparent=True) #dpi=100\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:43:01.415532Z",
     "start_time": "2018-10-24T17:43:00.239676Z"
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 10000\n",
    "\n",
    "m_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "k_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "\n",
    "m_enc = alice.predict([m_batch, k_batch])\n",
    "m_dec = (bob.predict([m_enc, k_batch]) > 0.5).astype(int)\n",
    "m_att = (eve.predict(m_enc) > 0.5).astype(int)\n",
    "\n",
    "bdiff = np.abs(m_batch - m_dec)\n",
    "bsum = np.sum(bdiff, axis=-1)\n",
    "ediff = np.abs(m_batch - m_att)\n",
    "esum = np.sum(ediff, axis=-1)\n",
    "\n",
    "print(\"Bob % correct: \", 100.0*np.sum(bsum == 0) / n_examples, '%')\n",
    "print(\"Eve % correct: \", 100.0*np.sum(esum == 0) / n_examples, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:40:45.280385Z",
     "start_time": "2018-10-24T17:40:45.004123Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "##### Alice network #####\n",
    "#\n",
    "ainput0 = Input(shape=(m_bits,)) #message\n",
    "ainput1 = Input(shape=(k_bits,)) #key\n",
    "ainput = concatenate([ainput0, ainput1], axis=1)\n",
    "\n",
    "adense1 = Dense(units=(m_bits + k_bits))(ainput)\n",
    "adense1a = Activation('tanh')(adense1)\n",
    "areshape = Reshape((m_bits + k_bits, 1,))(adense1a)\n",
    "\n",
    "aconv1 = Conv1D(filters=2, kernel_size=4, strides=1, padding=pad)(areshape)\n",
    "aconv1a = Activation('tanh')(aconv1)\n",
    "aconv2 = Conv1D(filters=4, kernel_size=2, strides=2, padding=pad)(aconv1a)\n",
    "aconv2a = Activation('tanh')(aconv2)\n",
    "aconv3 = Conv1D(filters=4, kernel_size=1, strides=1, padding=pad)(aconv2a)\n",
    "aconv3a = Activation('tanh')(aconv3)\n",
    "aconv4 = Conv1D(filters=1, kernel_size=1, strides=1, padding=pad)(aconv3a)\n",
    "\n",
    "aconv4a = Activation('sigmoid')(aconv4)\n",
    "\n",
    "\n",
    "\n",
    "aoutput = Flatten()(aconv4a)\n",
    "\n",
    "alice = Model([ainput0, ainput1], aoutput, name='alice')\n",
    "alice.summary()\n",
    "\n",
    "\n",
    "##### Bob network #####\n",
    "#\n",
    "binput0 = Input(shape=(c_bits,)) #ciphertext\n",
    "binput1 = Input(shape=(k_bits,)) #key\n",
    "binput = concatenate([binput0, binput1], axis=1)\n",
    "\n",
    "bdense1 = Dense(units=(c_bits + k_bits))(binput)\n",
    "bdense1a = Activation('tanh')(bdense1)\n",
    "\n",
    "breshape = Reshape((c_bits + k_bits, 1,))(bdense1a)\n",
    "\n",
    "bconv1 = Conv1D(filters=2, kernel_size=4, strides=1, padding=pad)(breshape)\n",
    "bconv1a = Activation('tanh')(bconv1)\n",
    "bconv2 = Conv1D(filters=4, kernel_size=2, strides=2, padding=pad)(bconv1a)\n",
    "bconv2a = Activation('tanh')(bconv2)\n",
    "bconv3 = Conv1D(filters=4, kernel_size=1, strides=1, padding=pad)(bconv2a)\n",
    "bconv3a = Activation('tanh')(bconv3)\n",
    "bconv4 = Conv1D(filters=1, kernel_size=1, strides=1, padding=pad)(bconv3a)\n",
    "bconv4a = Activation('sigmoid')(bconv4)\n",
    "\n",
    "boutput = Flatten()(bconv4a)\n",
    "\n",
    "bob = Model([binput0, binput1], boutput, name='bob')\n",
    "bob.summary()\n",
    "\n",
    "\n",
    "# Eve network\n",
    "#\n",
    "einput = Input(shape=(c_bits,)) #ciphertext only\n",
    "\n",
    "edense1 = Dense(units=(c_bits + k_bits))(einput)\n",
    "edense1a = Activation('tanh')(edense1)\n",
    "\n",
    "edense2 = Dense(units=(c_bits + k_bits))(edense1a)\n",
    "edense2a = Activation('tanh')(edense2)\n",
    "\n",
    "ereshape = Reshape((c_bits + k_bits, 1,))(edense2a)\n",
    "\n",
    "econv1 = Conv1D(filters=2, kernel_size=4, strides=1, padding=pad)(ereshape)\n",
    "econv1a = Activation('tanh')(econv1)\n",
    "econv2 = Conv1D(filters=4, kernel_size=2, strides=2, padding=pad)(econv1a)\n",
    "econv2a = Activation('tanh')(econv2)\n",
    "econv3 = Conv1D(filters=4, kernel_size=1, strides=1, padding=pad)(econv2a)\n",
    "econv3a = Activation('tanh')(econv3)\n",
    "econv4 = Conv1D(filters=1, kernel_size=1, strides=1, padding=pad)(econv3a)\n",
    "econv4a = Activation('sigmoid')(econv4)\n",
    "\n",
    "eoutput = Flatten()(econv4a)# Eve's attempt at code guessing\n",
    "\n",
    "eve = Model(einput, eoutput, name='eve')\n",
    "eve.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.compile(loss='mse', optimizer='sgd')\n",
    "bob.compile(loss='mse', optimizer='sgd')\n",
    "eve.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the communication channels by linking inputs to outputs\n",
    "#\n",
    "aliceout = alice([ainput0, ainput1])\n",
    "bobout = bob( [aliceout, binput1] )# bob sees ciphertext AND key\n",
    "eveout = eve( aliceout )# eve doesn't see the key, only the cipher\n",
    "\n",
    "# Loss for Eve is just L1 distance between ainput0 and eoutput. The sum\n",
    "# is taken over all the bits in the message. The quantity inside the K.mean()\n",
    "# is per-example loss. We take the average across the entire mini-batch\n",
    "#\n",
    "eveloss = K.mean(  K.sum(K.abs(ainput0 - eveout), axis=-1)  )\n",
    "\n",
    "# Loss for Alice-Bob communication depends on Bob's reconstruction, but\n",
    "# also on Eve's ability to decrypt the message. Eve should do no better\n",
    "# than random guessing, so on average she will guess half the bits right.\n",
    "#\n",
    "bobloss = K.mean(  K.sum(K.abs(ainput0 - bobout), axis=-1)  )\n",
    "abeloss = bobloss + K.square(m_bits/2 - eveloss)/( (m_bits//2)**2 )\n",
    "\n",
    "# Optimizer and compilation\n",
    "#\n",
    "abeoptim = RMSprop(lr=0.001)\n",
    "eveoptim = RMSprop(lr=0.001) #default 0.001\n",
    "\n",
    "\n",
    "# Build and compile the ABE model, used for training Alice-Bob networks\n",
    "#\n",
    "abemodel = Model([ainput0, ainput1, binput1], bobout, name='abemodel')\n",
    "abemodel.add_loss(abeloss)\n",
    "abemodel.compile(optimizer=abeoptim)\n",
    "\n",
    "\n",
    "# Build and compile the EVE model, used for training Eve net (with Alice frozen)\n",
    "#\n",
    "alice.trainable = False\n",
    "evemodel = Model([ainput0, ainput1], eveout, name='evemodel')\n",
    "evemodel.add_loss(eveloss)\n",
    "evemodel.compile(optimizer=eveoptim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abelosses = []\n",
    "boblosses = []\n",
    "evelosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T15:55:22.510714Z",
     "start_time": "2018-09-05T15:55:20.514083Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_encoded = encoder.predict(X_train, verbose=True)\n",
    "print(X_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a few of the encoded vectors' coodinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T17:53:31.379159Z",
     "start_time": "2018-10-24T17:53:29.209520Z"
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 10000\n",
    "showAll = True\n",
    "\n",
    "coord_indeces = np.array([\n",
    "    [ 0, 1, 2, 4],\n",
    "    [ 5, 6, 7, 14]\n",
    "])\n",
    "\n",
    "m_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "k_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "m_enc = alice.predict([m_batch, k_batch])\n",
    "\n",
    "if showAll:\n",
    "    n_cols = 4\n",
    "    n_rows = m_enc.shape[1] // n_cols\n",
    "else:\n",
    "    n_cols = coord_indeces.shape[1]\n",
    "    n_rows = coord_indeces.shape[0]\n",
    "\n",
    "plt.figure(figsize=(8, int(8.0/n_cols * n_rows)))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        i = row * n_cols + col\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        if showAll:\n",
    "            plt.title(\"Coord \" + str(i), fontsize=14)\n",
    "            plt.hist(m_enc[:, i], bins=20, density=True)\n",
    "        else:\n",
    "            plt.title(\"Coord \" + str(coord_indeces[row, col]), fontsize=12)\n",
    "            plt.hist(m_enc[:, coord_indeces[row, col]], bins=20, density=True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"images/\" + model_name + \"-encall.png\", transparent=True) #dpi=100\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:05:10.010121Z",
     "start_time": "2018-10-24T18:05:09.958705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's examine various correlations, if any\n",
    "data_arr = np.c_[m_batch, k_batch, m_enc]\n",
    "\n",
    "columns = [\n",
    "    'm0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11', 'm12', 'm13', 'm14', 'm15', \n",
    "    'k0', 'k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k10', 'k11', 'k12', 'k13', 'k14', 'k15', \n",
    "    'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', \n",
    "]\n",
    "\n",
    "data = pd.DataFrame(data=data_arr, index=range(10000), columns=columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:10:52.366126Z",
     "start_time": "2018-10-24T18:10:52.346180Z"
    }
   },
   "outputs": [],
   "source": [
    "datac = data[['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15']]\n",
    "datac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:11:00.899268Z",
     "start_time": "2018-10-24T18:11:00.692779Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corrc = datac.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:36:14.793195Z",
     "start_time": "2018-10-24T18:36:14.784219Z"
    }
   },
   "outputs": [],
   "source": [
    "corrc['c2'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:20:59.447103Z",
     "start_time": "2018-10-24T18:20:02.684246Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(datac, alpha=0.2, figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model `crypto2`\n",
    "\n",
    "Add dense, and allow tanh for codings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:25:37.704041Z",
     "start_time": "2018-10-23T16:25:37.698057Z"
    }
   },
   "outputs": [],
   "source": [
    "K.floatx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:22.648870Z",
     "start_time": "2018-10-24T18:44:22.644879Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'crypto2'\n",
    "\n",
    "# Set up the crypto parameters: message, key, and ciphertext bit lengths\n",
    "m_bits = 8\n",
    "k_bits = 8\n",
    "c_bits = 8\n",
    "pad = 'same'\n",
    "\n",
    "# Compute the size of the message space\n",
    "m_train = 2**(m_bits + k_bits)\n",
    "\n",
    "alice_file = 'models/crypto/' + model_name + '-alice'\n",
    "bob_file = 'models/crypto/' + model_name + '-bob'\n",
    "eve_file = 'models/crypto/' + model_name + '-eve'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:24.683326Z",
     "start_time": "2018-10-24T18:44:24.236485Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "kersize = 4\n",
    "\n",
    "##### Alice network #####\n",
    "#\n",
    "ainput0 = Input(shape=(m_bits,)) #message\n",
    "ainput1 = Input(shape=(k_bits,)) #key\n",
    "ainput = concatenate([ainput0, ainput1], axis=1)\n",
    "\n",
    "adense1 = Dense(units=(m_bits + k_bits))(ainput)\n",
    "adense1a = Activation('tanh')(adense1)\n",
    "\n",
    "areshape = Reshape((m_bits + k_bits, 1,))(adense1a)\n",
    "\n",
    "aconv1 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(areshape)\n",
    "aconv1a = Activation('tanh')(aconv1)\n",
    "aconv2 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(aconv1a)\n",
    "aconv2a = Activation('tanh')(aconv2)\n",
    "aconv3 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(aconv2a)\n",
    "aconv3a = Activation('tanh')(aconv3)\n",
    "aconv4 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(aconv3a)\n",
    "aconv4a = Activation('tanh')(aconv4)\n",
    "\n",
    "aflat = Flatten()(aconv4a)\n",
    "aoutput = Dense(units=c_bits, activation='tanh')(aflat) #ciphertext\n",
    "\n",
    "alice = Model([ainput0, ainput1], aoutput, name='alice')\n",
    "#alice.summary()\n",
    "\n",
    "\n",
    "##### Bob network #####\n",
    "#\n",
    "binput0 = Input(shape=(c_bits,)) #ciphertext\n",
    "binput1 = Input(shape=(k_bits,)) #key\n",
    "binput = concatenate([binput0, binput1], axis=1)\n",
    "\n",
    "bdense1 = Dense(units=(c_bits + k_bits))(binput)\n",
    "bdense1a = Activation('tanh')(bdense1)\n",
    "\n",
    "breshape = Reshape((c_bits + k_bits, 1,))(bdense1a)\n",
    "\n",
    "bconv1 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(breshape)\n",
    "bconv1a = Activation('tanh')(bconv1)\n",
    "bconv2 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(bconv1a)\n",
    "bconv2a = Activation('tanh')(bconv2)\n",
    "bconv3 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(bconv2a)\n",
    "bconv3a = Activation('tanh')(bconv3)\n",
    "bconv4 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(bconv3a)\n",
    "bconv4a = Activation('tanh')(bconv4)\n",
    "\n",
    "bflat = Flatten()(bconv4a)\n",
    "boutput = Dense(units=m_bits, activation='sigmoid')(bflat) #decrypted message\n",
    "\n",
    "bob = Model([binput0, binput1], boutput, name='bob')\n",
    "#bob.summary()\n",
    "\n",
    "\n",
    "# Eve network\n",
    "#\n",
    "einput = Input(shape=(c_bits,)) #ciphertext only\n",
    "\n",
    "edense1 = Dense(units=(c_bits + k_bits))(einput)\n",
    "edense1a = Activation('tanh')(edense1)\n",
    "edense2 = Dense(units=(m_bits + k_bits))(edense1a)\n",
    "edense2a = Activation('tanh')(edense2)\n",
    "\n",
    "ereshape = Reshape((m_bits + k_bits, 1,))(edense2a)\n",
    "\n",
    "econv1 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(ereshape)\n",
    "econv1a = Activation('tanh')(econv1)\n",
    "econv2 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(econv1a)\n",
    "econv2a = Activation('tanh')(econv2)\n",
    "econv3 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(econv2a)\n",
    "econv3a = Activation('tanh')(econv3)\n",
    "econv4 = Conv1D(filters=4, kernel_size=kersize, strides=1, padding=pad)(econv3a)\n",
    "econv4a = Activation('tanh')(econv4)\n",
    "\n",
    "eflat = Flatten()(econv4a)\n",
    "eoutput = Dense(units=m_bits, activation='sigmoid')(eflat) #code break attempt\n",
    "\n",
    "eve = Model(einput, eoutput, name='eve')\n",
    "#eve.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:24.906344Z",
     "start_time": "2018-10-24T18:44:24.814537Z"
    }
   },
   "outputs": [],
   "source": [
    "alice.compile(loss='mse', optimizer='sgd')\n",
    "bob.compile(loss='mse', optimizer='sgd')\n",
    "eve.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:25.141788Z",
     "start_time": "2018-10-24T18:44:25.137953Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    alice.summary()\n",
    "    bob.summary()\n",
    "    eve.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:29.268119Z",
     "start_time": "2018-10-24T18:44:28.613773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Establish the communication channels by linking inputs to outputs\n",
    "#\n",
    "aliceout = alice([ainput0, ainput1])\n",
    "bobout = bob( [aliceout, binput1] )# bob sees ciphertext AND key\n",
    "eveout = eve( aliceout )# eve doesn't see the key, only the cipher\n",
    "\n",
    "# Loss for Eve is just L1 distance between ainput0 and eoutput. The sum\n",
    "# is taken over all the bits in the message. The quantity inside the K.mean()\n",
    "# is per-example loss. We take the average across the entire mini-batch\n",
    "#\n",
    "eveloss = K.mean(  K.sum(K.abs(ainput0 - eveout), axis=-1)  )\n",
    "\n",
    "# Loss for Alice-Bob communication depends on Bob's reconstruction, but\n",
    "# also on Eve's ability to decrypt the message. Eve should do no better\n",
    "# than random guessing, so on average she will guess half the bits right.\n",
    "#\n",
    "bobloss = K.mean(  K.sum(K.abs(ainput0 - bobout), axis=-1)  )\n",
    "abeloss = bobloss + K.square(m_bits/2 - eveloss)/( (m_bits//2)**2 )\n",
    "\n",
    "# Optimizer and compilation\n",
    "#\n",
    "abeoptim = Adam()#RMSprop(lr=0.0015)\n",
    "eveoptim = Adam()#RMSprop(lr=0.0015) #default 0.001\n",
    "\n",
    "\n",
    "# Build and compile the ABE model, used for training Alice-Bob networks\n",
    "#\n",
    "abemodel = Model([ainput0, ainput1, binput1], bobout, name='abemodel')\n",
    "abemodel.add_loss(abeloss)\n",
    "abemodel.compile(optimizer=abeoptim)\n",
    "\n",
    "\n",
    "# Build and compile the EVE model, used for training Eve net (with Alice frozen)\n",
    "#\n",
    "alice.trainable = False\n",
    "evemodel = Model([ainput0, ainput1], eveout, name='evemodel')\n",
    "evemodel.add_loss(eveloss)\n",
    "evemodel.compile(optimizer=eveoptim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / save / restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T18:02:18.278616Z",
     "start_time": "2018-10-22T18:02:18.274601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep track of loss at every iteration for the final graph\n",
    "abelosses = []\n",
    "boblosses = []\n",
    "evelosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T18:07:39.372441Z",
     "start_time": "2018-10-22T18:02:18.642313Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 256\n",
    "n_batches = m_train // batch_size\n",
    "\n",
    "abecycles = 1\n",
    "evecycles = 2\n",
    "\n",
    "epoch = 0\n",
    "print(\"Training for\", n_epochs, \"epochs with\", n_batches, \"batches of size\", batch_size)\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    abelosses0 = [] #epoch-bound losses for text display during training\n",
    "    boblosses0 = []\n",
    "    evelosses0 = []\n",
    "    for iteration in range(n_batches):\n",
    "        \n",
    "        # Train the A-B+E network\n",
    "        #\n",
    "        alice.trainable = True\n",
    "        for cycle in range(abecycles):\n",
    "            # Select a random batch of messages, and a random batch of keys\n",
    "            #\n",
    "            m_batch = np.random.randint(0, 2, m_bits * batch_size).reshape(batch_size, m_bits)\n",
    "            k_batch = np.random.randint(0, 2, k_bits * batch_size).reshape(batch_size, k_bits)\n",
    "            loss = abemodel.train_on_batch([m_batch, k_batch, k_batch], None)\n",
    "        \n",
    "        abelosses0.append(loss)\n",
    "        abelosses.append(loss)\n",
    "        abeavg = np.mean(abelosses0)\n",
    "            \n",
    "        # Evaluate Bob's ability to decrypt a message\n",
    "        m_enc = alice.predict([m_batch, k_batch])\n",
    "        m_dec = bob.predict([m_enc, k_batch])\n",
    "        loss = np.mean(  np.sum( np.abs(m_batch - m_dec), axis=-1)  )\n",
    "        boblosses0.append(loss)\n",
    "        boblosses.append(loss)\n",
    "        bobavg = np.mean(boblosses0)\n",
    "        \n",
    "        # Train the EVE network\n",
    "        #\n",
    "        alice.trainable = False\n",
    "        for cycle in range(evecycles):\n",
    "            m_batch = np.random.randint(0, 2, m_bits * batch_size).reshape(batch_size, m_bits)\n",
    "            k_batch = np.random.randint(0, 2, k_bits * batch_size).reshape(batch_size, k_bits)\n",
    "            loss = evemodel.train_on_batch([m_batch, k_batch], None)\n",
    "        \n",
    "        evelosses0.append(loss)\n",
    "        evelosses.append(loss)\n",
    "        eveavg = np.mean(evelosses0)\n",
    "        \n",
    "        if iteration % max(1, (n_batches // 100)) == 0:\n",
    "            print(\"\\rEpoch {:3}: {:3}% | abe: {:2.3f} | eve: {:2.3f} | bob: {:2.3f}\".format(\n",
    "                epoch, 100 * iteration // n_batches, abeavg, eveavg, bobavg), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    print()\n",
    "    epoch += 1\n",
    "    \n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T18:21:22.283022Z",
     "start_time": "2018-10-22T18:21:22.051641Z"
    }
   },
   "outputs": [],
   "source": [
    "steps = -1\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(abelosses[:steps], label='A-B', alpha=0.99)\n",
    "plt.plot(evelosses[:steps], label='Eve', alpha=0.99)\n",
    "plt.plot(boblosses[:steps], label='Bob', alpha=0.99)\n",
    "plt.xlabel(\"Iterations\", fontsize=13)\n",
    "plt.ylabel(\"Loss\", fontsize=13)\n",
    "plt.legend(fontsize=13, loc='upper right')\n",
    "\n",
    "#plt.savefig(\"images/\" + model_name + \"-all.png\", transparent=True) #dpi=100\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T18:21:34.181962Z",
     "start_time": "2018-10-22T18:21:33.878104Z"
    }
   },
   "outputs": [],
   "source": [
    "alice.save(alice_file + '.h5', overwrite=True)\n",
    "bob.save(bob_file + '.h5', overwrite=True)\n",
    "eve.save(eve_file + '.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:45.640423Z",
     "start_time": "2018-10-24T18:44:43.968780Z"
    }
   },
   "outputs": [],
   "source": [
    "alice = load_model(alice_file + '.h5')\n",
    "bob = load_model(bob_file + '.h5')\n",
    "eve = load_model(eve_file + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T18:44:50.203896Z",
     "start_time": "2018-10-24T18:44:48.270065Z"
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 10000\n",
    "\n",
    "m_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "k_batch = np.random.randint(0, 2, m_bits * n_examples).reshape(n_examples, m_bits)\n",
    "\n",
    "m_enc = alice.predict([m_batch, k_batch])\n",
    "#m_enc = np.round(m_enc, 3)\n",
    "m_dec = (bob.predict([m_enc, k_batch]) > 0.5).astype(int)\n",
    "m_att = (eve.predict(m_enc) > 0.5).astype(int)\n",
    "\n",
    "bdiff = np.abs(m_batch - m_dec)\n",
    "bsum = np.sum(bdiff, axis=-1)\n",
    "ediff = np.abs(m_batch - m_att)\n",
    "esum = np.sum(ediff, axis=-1)\n",
    "\n",
    "print(\"Bob % correct: \", 100.0*np.sum(bsum == 0) / n_examples, '%')\n",
    "print(\"Eve % correct: \", 100.0*np.sum(esum == 0) / n_examples, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T01:34:55.867773Z",
     "start_time": "2018-10-24T01:34:55.863813Z"
    }
   },
   "source": [
    "# Asymmetric (public-key) encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model crypto3 (Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T09:29:24.324720Z",
     "start_time": "2018-10-24T09:29:24.320759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-based encryption (POC)\n",
    "\n",
    "Let's take model `crypto2`, for which Bob was incredibly accurate while Eve failed to decrypt the messages.\n",
    "\n",
    "We construct a full encryption, with 32-bit float ciphertexts (vector of dim 8), so each character will encode to 32 * 8 = 256 bits\n",
    "\n",
    "**Encryption Algorithm:**\n",
    "* Convert character string to binary\n",
    "* Pad the binary char encoding string wtih 3 random bits to get a block of 8 bits per character\n",
    "* Pass 8-bit blocks of the string through the encryption network Bob\n",
    "* The output is 8-dim vectors of type `float32`, for a total of $8 \\cdot 32 = 256$ bits per character\n",
    "* Convert the output to a binary string by concatenating the binary representation of each component the 8-dim float vector. **This is the encoding**\n",
    "\n",
    "One could convert this to a character string to see what the messasge might look like. Each character will be a block of 5 (remove 3 bits for padding).\n",
    "\n",
    "The decryption algorithm is the reverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T19:00:10.570167Z",
     "start_time": "2018-10-24T19:00:08.879925Z"
    }
   },
   "outputs": [],
   "source": [
    "alice = load_model('models/crypto/crypto2-alice.h5')\n",
    "bob = load_model('models/crypto/crypto2-bob.h5')\n",
    "eve = load_model('models/crypto/crypto2-eve.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char map and str functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T19:00:12.822185Z",
     "start_time": "2018-10-24T19:00:12.811252Z"
    }
   },
   "outputs": [],
   "source": [
    "block_size_unpadded = 5\n",
    "block_padding = 3\n",
    "block_size = block_size_unpadded + block_padding\n",
    "\n",
    "chrlist = [\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n",
    "    'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n",
    "    'u', 'v', 'w', 'x', 'y', 'z', '.', ',', '!', '?',\n",
    "    ':', ' '\n",
    "]\n",
    "binlist = [\n",
    "    '00000', '00001', '00010', '00011', '00100', \n",
    "    '00101', '00110', '00111', '01000', '01001',\n",
    "    '01010', '01011', '01100', '01101', '01110', \n",
    "    '01111', '10000', '10001', '10010', '10011',\n",
    "    '10100', '10101', '10110', '10111', '11000',\n",
    "    '11001', '11010', '11011', '11100', '11101', \n",
    "    '11110', '11111'\n",
    "]\n",
    "\n",
    "def randombits(n):\n",
    "    if n == 0:\n",
    "        return ''\n",
    "    decvalue = np.random.randint(0, 2**n)\n",
    "    formatstring = '0' + str(n) + 'b'\n",
    "    return format(decvalue, formatstring)\n",
    "\n",
    "def encstr(message, block_padding=0):\n",
    "    cipher = \"\"\n",
    "    for c in message:\n",
    "        binstr = binlist[chrlist.index(c)]\n",
    "        binstrpadded = randombits(block_padding) + str(binstr)\n",
    "        cipher = cipher + binstrpadded\n",
    "    return cipher, len(message)\n",
    "\n",
    "def decstr(cipher, n, block_padding=0):\n",
    "    message = \"\"\n",
    "    cipherlength = len(cipher)\n",
    "    block_size = cipherlength // n\n",
    "    for i in range(n):\n",
    "        blockpadded = cipher[block_size*i : block_size*i + block_size]\n",
    "        blockunpadded = blockpadded[block_padding:]\n",
    "        character = chrlist[binlist.index(blockunpadded)]\n",
    "        message = message + character\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T19:03:18.597023Z",
     "start_time": "2018-10-24T19:03:18.593048Z"
    }
   },
   "outputs": [],
   "source": [
    "print(encstr('adi', 3))\n",
    "print(decstr('00010011010001001001001001010011', 4, block_padding=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T19:00:16.375072Z",
     "start_time": "2018-10-24T19:00:16.369288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for converting float to 32-bit binary string\n",
    "def float_to_binary(value):\n",
    "    binNum = bin(  ctypes.c_uint.from_buffer(ctypes.c_float(value)).value  )[2:]\n",
    "    binstr = binNum.rjust(32,\"0\")\n",
    "    return binstr\n",
    "\n",
    "def binary_to_float(binstr):\n",
    "    intvalue = int(binstr, 2)\n",
    "    floatvalue = ctypes.c_float.from_buffer(ctypes.c_uint(intvalue))\n",
    "    return floatvalue.value\n",
    "\n",
    "# Convert a positive integer num into a bit vector of 'bits' size\n",
    "def bitarray(num, bits):\n",
    "    return np.array(list(np.binary_repr(num).zfill(bits))).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T19:23:00.850494Z",
     "start_time": "2018-10-24T19:23:00.577196Z"
    }
   },
   "outputs": [],
   "source": [
    "key = np.array([[0,0,0,0,0,0,0,0]])\n",
    "m = 'adi'\n",
    "\n",
    "m_bin, _ = encstr(m, block_padding=3)\n",
    "m_bin_len = len(m_bin)\n",
    "print(m_bin, m_bin_len)\n",
    "\n",
    "ciphertext = \"\"\n",
    "for i in range(m_bin_len // m_bits):\n",
    "    # read blocks of size m_bits\n",
    "    binblockstr = m_bin[m_bits*i : m_bits*i + m_bits]\n",
    "    binblock = np.array(list(binblockstr)).astype(np.int8).reshape(1, m_bits)\n",
    "    \n",
    "    floatVector = alice.predict([binblock, key])\n",
    "    #print(np.round(floatVector,3))\n",
    "    \n",
    "    # convert each coordinate of the cipher (float) vector to binary\n",
    "    # and construct the binary ciphertext\n",
    "    for j in range(c_bits):\n",
    "        ciphertext = ciphertext + float_to_binary(floatVector[0][j])\n",
    "        #print(float_to_binary(floatVector[0][j]))\n",
    "\n",
    "#print(ciphertext, len(ciphertext)) # ciphertext in binary\n",
    "print(decstr(ciphertext, n=(len(ciphertext)//8), block_padding=3)) #ciphertext as characters\n",
    "\n",
    "ciphertext_len = len(ciphertext)\n",
    "plaintextbin = \"\"\n",
    "for i in range(ciphertext_len // (c_bits*32)):\n",
    "    # read the ciphertext in chunks of 32*c_bits bits, i.e one encoding at a time\n",
    "    floatVectorbin = ciphertext[c_bits*32*i : c_bits*32*i + c_bits*32]\n",
    "    #print(floatVectorbin)\n",
    "    # convert the binary chunk to an 8-dim float vector (input for AI Bob)\n",
    "    floatVector = np.zeros(c_bits, dtype=np.float32).reshape(1, c_bits)\n",
    "    for j in range(len(floatVectorbin) // 32):\n",
    "        floatValuebin = floatVectorbin[32*j : 32*j + 32]\n",
    "        #print(floatValuebin)\n",
    "        floatValue = binary_to_float(floatValuebin)\n",
    "        floatVector[0][j] = floatValue\n",
    "    #print(np.round(floatVector,3))\n",
    "    \n",
    "    charbinvector = list( (bob.predict([floatVector, key]) > 0.5)[0].astype(int) )\n",
    "    for j in range(len(charbinvector)):\n",
    "        plaintextbin = plaintextbin + str(charbinvector[j])\n",
    "\n",
    "print(plaintextbin)\n",
    "\n",
    "m_dec = \"\"\n",
    "for i in range(len(plaintextbin) // m_bits):\n",
    "    strbin = plaintextbin[m_bits*i : m_bits*i + m_bits]\n",
    "    m_dec = m_dec + decstr(strbin, len(strbin)//m_bits, block_padding=3)\n",
    "\n",
    "print(m_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T19:08:38.135699Z",
     "start_time": "2018-10-24T19:08:38.119739Z"
    }
   },
   "outputs": [],
   "source": [
    "# How would Eve peform on the above ciphertext?\n",
    "\n",
    "plaintextbin = \"\"\n",
    "for i in range(ciphertext_len // (c_bits*32)):\n",
    "    floatVectorbin = ciphertext[c_bits*32*i : c_bits*32*i + c_bits*32]\n",
    "    floatVector = np.zeros(c_bits, dtype=np.float32).reshape(1, c_bits)\n",
    "    for j in range(len(floatVectorbin) // 32):\n",
    "        floatValuebin = floatVectorbin[32*j : 32*j + 32]\n",
    "        floatValue = binary_to_float(floatValuebin)\n",
    "        floatVector[0][j] = floatValue\n",
    "    charbinvector = (eve.predict(floatVector) > 0.5).astype(int)\n",
    "    for j in range(charbinvector.shape[1]):\n",
    "        plaintextbin = plaintextbin + str(charbinvector[0][j])\n",
    "\n",
    "print(plaintextbin)\n",
    "\n",
    "m_dec = \"\"\n",
    "for i in range(len(plaintextbin) // m_bits):\n",
    "    strbin = plaintextbin[m_bits*i : m_bits*i + m_bits]\n",
    "    m_dec = m_dec + decstr(strbin, len(strbin)//m_bits, block_padding=3)\n",
    "\n",
    "print(m_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.068px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
